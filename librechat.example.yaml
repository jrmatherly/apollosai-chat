# ApollosAI Configuration (Example)
# Reference: .scratchpad/project-enhancement/SELF-HOSTING-GUIDE.md
#
# Copy this file to librechat.yaml and update with your actual values.
# Environment variables use ${VAR_NAME} syntax and are resolved at runtime.

version: 1.3.4

cache: true

# File storage strategies — S3 for documents, local for persistent-URL assets
# (S3 presigned URLs expire; local provides persistent URLs for avatars/images)
fileStrategy: 's3'
fileStrategies:
  default: 's3'
  avatar: 'local'
  image: 'local'
imageOutputType: 'webp'
secureImageLinks: true

# Registration — OpenID (Microsoft Entra) only
registration:
  socialLogins: ['openid']
  # Restrict registration to specific email domains (recommended for enterprise)
  # allowedDomains:
  #   - 'yourdomain.com'

# Web Search — Self-hosted SearXNG + Firecrawl
webSearch:
  # Search Provider Configuration
  searxngInstanceUrl: '${SEARXNG_INSTANCE_URL}'
  searxngApiKey: '${SEARXNG_API_KEY}'
  searchProvider: 'searxng'

  # Scraper Configuration
  firecrawlApiKey: '${FIRECRAWL_API_KEY}'
  firecrawlApiUrl: '${FIRECRAWL_API_URL}'
  firecrawlVersion: '${FIRECRAWL_VERSION}'
  firecrawlOptions:
    formats: ['markdown', 'rawHtml']
    includeTags: ['main', 'article', '.content']
    excludeTags: ['nav', 'footer', '.ads']
    waitFor: 2000
    timeout: 10000
    mobile: false
    blockAds: true
    onlyMainContent: true
    removeBase64Images: true
    maxAge: 3600000
    location:
      country: 'US'
      languages: ['en']
  scraperProvider: 'firecrawl'

  # Reranker — Cohere via LiteLLM proxy (optional)
  # cohereApiKey: '${COHERE_API_KEY}'
  # cohereApiUrl: '${COHERE_API_URL}'
  # rerankerType: 'cohere'

  # General Settings
  scraperTimeout: 7500
  safeSearch: 1

# OCR — Mistral via LiteLLM proxy
ocr:
  strategy: 'azure_mistral_ocr'
  mistralModel: 'mistral-ocr-latest'
  apiKey: '${OCR_API_KEY}'
  baseURL: '${OCR_BASEURL}'

# File handling — server limits, MIME types, and client-side optimization
fileConfig:
  serverFileSizeLimit: 100
  avatarSizeLimit: 2
  fileTokenLimit: 100000
  imageGeneration:
    percentage: 100
    px: 1024
  endpoints:
    default:
      fileLimit: 10
      fileSizeLimit: 25
      totalSizeLimit: 20
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/json"
        - "application/xml"
        - "application/vnd\\.openxmlformats-officedocument\\..+"
        - "application/(msword|vnd\\.ms-excel|vnd\\.ms-powerpoint)"
        - "application/octet-stream"
    agents:
      fileLimit: 10
      fileSizeLimit: 25
      totalSizeLimit: 50
      supportedMimeTypes:
        # ── Programming languages — regex patterns (matches code-interpreter) ──
        - "text/x-python.*"                   # .py (covers x-python, x-python-script, x-python-code)
        - "application/x-python.*"            # .py (alt MIME variants)
        - "text/(javascript|typescript)"      # .js, .ts
        - "application/(javascript|typescript)" # .js, .ts (alt)
        - "text/x-(go|java-source|csrc|c\\+\\+src|chdr|c\\+\\+hdr)" # .go, .java, .c, .cpp, .h, .hpp
        - "text/x-(php|rustsrc|r-source|fortran|d)" # .php, .rs, .r, .f90, .d
        - "application/x-httpd-php"           # .php (alt)
        # ── Data & config formats ──
        - "application/json"                  # .json
        - "application/x-ndjson"              # .ndjson / .jsonl
        - "application/xml"                   # .xml
        - "text/(xml|csv|tab-separated-values)" # .xml, .csv, .tsv
        - "application/x-yaml"               # .yaml / .yml
        - "text/yaml"                         # .yaml (alt)
        - "application/toml"                  # .toml
        # ── Documents & text ──
        - "text/(plain|markdown|html|css)"    # .txt, .log, .env, .md, .html, .css
        - "application/pdf"                   # .pdf
        - "application/vnd\\.openxmlformats-officedocument\\..+" # .docx, .xlsx, .pptx
        - "application/(msword|vnd\\.ms-excel|vnd\\.ms-powerpoint)" # .doc, .xls, .ppt
        # ── Shell & scripts ──
        - "application/x-sh(ellscript)?"      # .sh
        - "text/x-shellscript"                # .sh (alt)
        # ── Images (for vision/analysis) ──
        - "image/.*"                          # all image types
        # ── Archives ──
        - "application/(zip|gzip|x-tar)"      # .zip, .gz, .tar
        # ── Fallback (browsers send this for unknown extensions) ──
        - "application/octet-stream"
  # Text file processing — "Upload as Text" feature
  text:
    supportedMimeTypes:
      - "^text/(plain|markdown|csv|json|xml|html|css|javascript|typescript|x-python|x-java|x-csharp|x-php|x-ruby|x-go|x-rust|x-kotlin|x-swift|x-scala|x-perl|x-lua|x-shell|x-sql|x-yaml|x-toml)$"
  # OCR file processing — enhanced extraction for images and scanned docs
  ocr:
    supportedMimeTypes:
      - "^image/(jpeg|gif|png|webp|heic|heif)$"
      - "^application/pdf$"
      - "^application/vnd\\.openxmlformats-officedocument\\.(wordprocessingml\\.document|presentationml\\.presentation|spreadsheetml\\.sheet)$"
      - "^application/vnd\\.ms-(word|powerpoint|excel)$"
      - "^application/epub\\+zip$"
  # Speech-to-text file processing
  stt:
    supportedMimeTypes:
      - "^audio/(mp3|mpeg|mpeg3|wav|wave|x-wav|ogg|vorbis|mp4|x-m4a|flac|x-flac|webm)$"
  clientImageResize:
    enabled: true
    maxWidth: 1920
    maxHeight: 1080
    quality: 0.8
    compressFormat: 'webp'

# Rate limits — file uploads, conversation imports, speech
rateLimits:
  fileUploads:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60
  conversationsImport:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60
  stt:
    ipMax: 100
    ipWindowInMinutes: 1
    userMax: 50
    userWindowInMinutes: 1
  tts:
    ipMax: 100
    ipWindowInMinutes: 1
    userMax: 50
    userWindowInMinutes: 1

# Agent Actions domain restrictions (SSRF protection)
# If not configured, SSRF targets are blocked (localhost, private IPs, .internal/.local TLDs).
# To allow internal targets, you MUST explicitly add them.
actions:
  allowedDomains:
    - 'host.docker.internal'
    - 'localhost'

# Endpoint configuration
endpoints:
  agents:
    streamRate: 20
    disableBuilder: false
    recursionLimit: 50
    maxRecursionLimit: 100
    allowedProviders:
      - azureOpenAI
    capabilities:
      - 'execute_code'
      - 'file_search'
      - 'actions'
      - 'tools'
      - 'artifacts'
      - 'context'
      - 'ocr'
      - 'chain'
      - 'web_search'
    maxCitations: 30
    maxCitationsPerFile: 7
    minRelevanceScore: 0.45
  azureOpenAI:
    streamRate: 30
    titleModel: 'your-title-model'
    titleConvo: true
    titleMethod: 'completion'
    groups:
      - group: 'primary'
        apiKey: '${AZURE_OPENAI_API_KEY}'
        instanceName: '${AZURE_OPENAI_INSTANCE}'
        version: '${AZURE_OPENAI_API_VERSION}'
        dropParams: ['user']
        models:
          your-model-name:
            deploymentName: '${AZURE_MODEL_DEPLOYMENT}'
          # Add more models as needed:
          # another-model:
          #   deploymentName: '${AZURE_ANOTHER_DEPLOYMENT}'
  all:
    streamRate: 25
    titleConvo: true
    titleModel: 'your-title-model'
    titleMethod: 'completion'
    titlePrompt: |
      Analyze this conversation and provide:
      1. A concise title in the detected language (5 words or fewer, no punctuation or quotation marks)
      2. Always start with a relevant emoji

      {convo}

  # Custom endpoints via LiteLLM proxy or other providers (optional)
  # custom:
  #   - name: 'LiteLLM'
  #     apiKey: '${LITELLM_API_KEY}'
  #     baseURL: '${LITELLM_BASE_URL}'
  #     models:
  #       default: ['model-1', 'model-2']
  #       fetch: true
  #     titleConvo: true
  #     titleModel: 'your-title-model'
  #     modelDisplayLabel: 'LiteLLM'

# UI feature toggles
interface:
  customWelcome: 'Welcome to Your App, {{user.name}}'
  privacyPolicy:
    externalUrl: 'https://example.com/privacy'
    openNewTab: true
  termsOfService:
    externalUrl: 'https://example.com/terms'
    openNewTab: true
    modalAcceptance: true
    modalTitle: 'Terms of Service'
    modalContent: |
      # Terms of Service

      By using this platform, you agree to the following:

      - This platform is for authorized users only
      - All conversations may be monitored for security and compliance
      - Do not share confidential or proprietary information beyond what is necessary
      - AI-generated content should be reviewed before use in official communications

      For the full terms, visit [example.com/terms](https://example.com/terms).
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  bookmarks: true
  multiConvo: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: false
  mcpServers:
    use: true
    create: false
    share: false
    public: false
    trustCheckbox:
      label: 'I trust this MCP server'
      subLabel: 'Only enable servers approved by your IT team'
  agents:
    use: true
    create: true
    share: true
    public: false
  remoteAgents:
    use: true
    create: true
    share: false
    public: false
  prompts:
    use: true
    create: true
    share: true
    public: false
  webSearch: true
  runCode: true
  fileSearch: true
  fileCitations: true
  memories: true
  temporaryChat: true
  temporaryChatRetention: 720

# Memory system — AI-driven conversation memory
memory:
  disabled: false
  tokenLimit: 3000
  charLimit: 10000
  personalize: true
  messageWindowSize: 8
  validKeys:
    - 'user_preferences'
    - 'conversation_context'
    - 'learned_facts'
    - 'personal_information'
  agent:
    provider: 'azureOpenAI'
    model: 'your-memory-model'
    instructions: |
      Store memory using only these categories:
      - user_preferences: Explicitly stated preferences about communication style, tools, or workflow
      - conversation_context: Ongoing projects, topics, or tasks the user is working on
      - learned_facts: Objective information or facts mentioned during conversations
      - personal_information: Only what the user explicitly shares about themselves
      Delete outdated or corrected information promptly. Never infer or assume — only store what is explicitly stated.
    model_parameters:
      temperature: 0.2
      max_tokens: 1500

# Speech — TTS/STT configuration
# IMPORTANT: Never hardcode API keys here — use ${ENV_VAR} references
speech:
  tts:
    openai:
      url: '${AZURE_TTS_URL}'
      apiKey: '${AZURE_TTS_API_KEY}'
      model: 'tts-1'
      voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']
  stt:
    openai:
      url: '${STT_BASE_URL}'
      apiKey: '${STT_API_KEY}'
      model: 'whisper-1'
  speechTab:
    conversationMode: false
    advancedMode: false
    speechToText:
      engineSTT: 'openai'
      autoTranscribeAudio: true
      decibelValue: -45
    textToSpeech:
      engineTTS: 'openai'
      voice: 'nova'
      automaticPlayback: false
      playbackRate: 1.0
      cacheTTS: true

# Transaction tracking — records token usage per user/conversation
transactions:
  enabled: true

# Token balance — track-only mode (effectively unlimited)
balance:
  enabled: true
  startBalance: 10000000
  autoRefillEnabled: true
  refillIntervalValue: 1
  refillIntervalUnit: 'days'
  refillAmount: 10000000

# MCP — SSRF protection allowlist
mcpSettings:
  allowedDomains:
    - 'host.docker.internal'
    - '*.docker.internal'
    - 'localhost'
    # Add container names that MCP servers need to reach:
    # - 'your-mcp-container'

# MCP Servers (optional)
# mcpServers:
#   your-mcp-server:
#     type: streamable-http
#     url: http://host.docker.internal:8080/mcp/
#     title: 'Your MCP Server'
#     description: 'Description of your MCP server'
#     timeout: 60000
#     initTimeout: 30000
#     apiKey:
#       source: admin
#       authorization_type: bearer
#       key: '${MCP_SERVER_TOKEN}'
#     headers:
#       X-User-ID: '{{LIBRECHAT_USER_ID}}'
#       X-User-Email: '{{LIBRECHAT_USER_EMAIL}}'
#       X-User-Name: '{{LIBRECHAT_USER_NAME}}'
#       X-User-Username: '{{LIBRECHAT_USER_USERNAME}}'
#       X-User-Role: '{{LIBRECHAT_USER_ROLE}}'
#     startup: true
#     chatMenu: true
#     serverInstructions: true

# Model Specs — curated AI personas (optional)
# modelSpecs:
#   enforce: false
#   prioritize: true
#   list:
#     - name: 'assistant-balanced'
#       label: 'Assistant — Balanced'
#       default: true
#       description: 'General-purpose assistant for everyday tasks.'
#       group: 'Your App'
#       webSearch: true
#       fileSearch: true
#       artifacts: true
#       mcpServers:
#         - 'your-mcp-server'
#       preset:
#         endpoint: 'azureOpenAI'
#         model: 'your-default-model'
#         modelLabel: 'Assistant Balanced'
#         temperature: 0.7
#         maxContextTokens: 128000
#         max_tokens: 4096
#         greeting: "Hi! How can I help you today?"
#         promptPrefix: |
#           You are a helpful AI assistant. Be concise and professional.
#
#     - name: 'assistant-advanced'
#       label: 'Assistant — Advanced'
#       description: 'Full-power reasoning for complex analysis.'
#       group: 'Your App'
#       webSearch: true
#       fileSearch: true
#       artifacts: true
#       mcpServers:
#         - 'your-mcp-server'
#       preset:
#         endpoint: 'azureOpenAI'
#         model: 'your-advanced-model'
#         modelLabel: 'Assistant Advanced'
#         temperature: 0.5
#         maxContextTokens: 128000
#         max_tokens: 8192
#         imageDetail: 'high'
#         reasoning_effort: 'high'
#         reasoning_summary: 'concise'
#         greeting: 'Ready for deep work. What are we tackling?'
#
#     - name: 'assistant-code'
#       label: 'Assistant — Code'
#       description: 'Specialized for code generation and debugging.'
#       group: 'Your App'
#       webSearch: true
#       fileSearch: true
#       executeCode: true
#       artifacts: true
#       mcpServers:
#         - 'your-mcp-server'
#       preset:
#         endpoint: 'azureOpenAI'
#         model: 'your-code-model'
#         modelLabel: 'Assistant Code'
#         temperature: 0.3
#         maxContextTokens: 128000
#         max_tokens: 8192
#         greeting: 'Code mode activated. What are we building?'
#         promptPrefix: |
#           You are a senior software engineer. Write clean, well-documented code.
#
#     - name: 'assistant-quick'
#       label: 'Assistant — Quick'
#       description: 'Ultra-fast responses for simple questions.'
#       group: 'Your App'
#       webSearch: true
#       preset:
#         endpoint: 'azureOpenAI'
#         model: 'your-fast-model'
#         modelLabel: 'Assistant Quick'
#         temperature: 0.5
#         maxContextTokens: 32000
#         max_tokens: 2048
#   addedEndpoints:
#     - azureOpenAI
#     - agents
